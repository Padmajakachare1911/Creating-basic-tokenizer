# Creating-basic-tokenizer
A Python function to implement a basic tokenization algorithm for a given language.

# Task 1 - Basic Tokenizer

## ðŸ“Œ Description
This notebook contains a basic tokenizer function implemented in Python. It processes text input by converting to lowercase, removing punctuation, and splitting into individual words.

## âœ… Technologies Used
- Python
- scikit-learn (for evaluation metrics)

## ðŸ“Š Evaluation
Simulated evaluation metrics (confusion matrix, precision, recall, accuracy) are included for token comparison. Accuracy exceeds 70%.

## ðŸ“‚ Files Included
- `tokenizer.ipynb`
- `requirements.txt`
